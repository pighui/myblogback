<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
    <meta charset="utf-8">
    
<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','/js/analytics.js','ga');

ga('create', 'UA-135687698-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->


    
    <title>
        爬虫入门之Python中urllib库的使用 |
        
        欢迎浏览本博客</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    
    
        <meta name="keywords" content="Ubuntu,Linux,Python,Python Web,爬虫,数据分析,机器学习">
    
    <meta name="description" content="本文将使用三个例子，带大家了解urllib库的使用方法。 安装包： 1pip install urllib 1.提取网页中的图片链接并下载">
<meta name="keywords" content="爬虫,Python">
<meta property="og:type" content="article">
<meta property="og:title" content="爬虫入门之Python中urllib库的使用">
<meta property="og:url" content="https://www.xuhuiblog.cn/爬虫/爬虫入门之Python中urllib库的使用/index.html">
<meta property="og:site_name" content="欢迎浏览本博客">
<meta property="og:description" content="本文将使用三个例子，带大家了解urllib库的使用方法。 安装包： 1pip install urllib 1.提取网页中的图片链接并下载">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://www.xuhuiblog.cn/爬虫/爬虫入门之Python中urllib库的使用/1.png">
<meta property="og:updated_time" content="2019-04-22T12:20:42.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="爬虫入门之Python中urllib库的使用">
<meta name="twitter:description" content="本文将使用三个例子，带大家了解urllib库的使用方法。 安装包： 1pip install urllib 1.提取网页中的图片链接并下载">
<meta name="twitter:image" content="https://www.xuhuiblog.cn/爬虫/爬虫入门之Python中urllib库的使用/1.png">
    
        <link rel="alternate" href="/atom.xml" title="欢迎浏览本博客" type="application/atom+xml">
    
    
        <link rel="icon" href="/images/favicon.ico">
    
    
        <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
    
    <link rel="stylesheet" href="/css/style.css">
    <link rel="stylesheet" href="/css/highlight.css">
    <script>
        let antiquityStorage = window.sessionStorage.getItem('antiquitySessionStorage');
        if (antiquityStorage == '' || antiquityStorage == null) {
            var antiquityLoader = '<div id="loaderbox"><div class="loader"><div class="load-roll"><div class="load-top"></div><div class="load-right"></div><div class="load-bottom"></div></div></div></div>';
            document.write(antiquityLoader);
            document.body.style.overflow = 'hidden'
        }
    </script>
</head>
</html>
<body>
<div id="fullpage" class="mobile-nav-right">
    
    <div id="wrapper" style="background-image: url(/images/bg.jpg)"
         title="图片来自网络">
        

            <header id="header">
  <div id="nav-toggle" class="nav-toggle"></div>
  <div class="head-box global-width">
    <nav class="nav-box nav-right">
      
        <a class="nav-item" href="/" title>首页</a>
      
        <a class="nav-item" href="https://github.com/pighui" title>基友</a>
      
        <a class="nav-item" href="/archives" title>文章</a>
      
        <a class="nav-item" href="/me" title>简历</a>
      
        <a class="nav-item" href="/snow" title>看雪</a>
      
    </nav>
  </div>
</header>
            <div id="middlecontent" title class="global-width sidebar-right">
                <section id="main"><article id="post-爬虫入门之Python中urllib库的使用" class="article global-container article-type-post" itemscope itemprop="blogPost">
  
    <header class="article-header">
      
  
    <h1 class="article-title" itemprop="name">
      爬虫入门之Python中urllib库的使用
    </h1>
  

    </header>
  
  <div class="article-meta">
    <a href="/爬虫/爬虫入门之Python中urllib库的使用/" class="article-date">
  <time datetime="2019-04-17T12:18:56.000Z" itemprop="datePublished">2019-04-17</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/爬虫/">爬虫</a>
  </div>

    
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python/">Python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/爬虫/">爬虫</a></li></ul>

  </div>
  
    <span id="busuanzi_container_page_pv">
      本文总阅读量<span id="busuanzi_value_page_pv"></span>次
    </span>
  

  <div class="article-inner">
    
    <div class="article-content article-content-cloud" itemprop="articleBody">
      
        <p>本文将使用三个例子，带大家了解urllib库的使用方法。</p>
<p>安装包：</p>
<div class="highlight-box" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install urllib</span><br></pre></td></tr></table></figure></div>
<h4 id="1-提取网页中的图片链接并下载"><a href="#1-提取网页中的图片链接并下载" class="headerlink" title="1.提取网页中的图片链接并下载"></a>1.提取网页中的图片链接并下载</h4><a id="more"></a>
<p>使用urllib下载网页<br>1) urllib.request.urlopen() 打开网页<br>2) urllib.request.urlretrieve()  下载网页到文件中<br>3）response 响应对象</p>
<p>​    code/status 响应状态码</p>
<p>​    headers/info 请求头</p>
<p>​    read() 响应的字节数据</p>
<p>​    readline()/readlines() 响应的文本的数据</p>
<div class="highlight-box" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#! /usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*-coding:UTF-8-*-</span></span><br><span class="line"><span class="comment">#__author__ : pighui</span></span><br><span class="line"><span class="comment">#__time__ : 2019-4-17 上午11:01</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> http.client <span class="keyword">import</span> HTTPResponse</span><br><span class="line"><span class="keyword">from</span> threading <span class="keyword">import</span> Thread</span><br><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen, urlretrieve</span><br><span class="line"><span class="comment"># 解决ssl证书的问题</span></span><br><span class="line"><span class="keyword">import</span> ssl</span><br><span class="line">ssl._create_default_https_context = ssl._create_unverified_context</span><br><span class="line"><span class="keyword">from</span> util.md5_format <span class="keyword">import</span> md5_code</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="comment"># 下载（请求）url</span></span><br><span class="line">    <span class="comment"># 如果data参数不为空，则表示本次请求的方法是POST,反之为GET</span></span><br><span class="line">    response: HTTPResponse = urlopen(url)</span><br><span class="line">    <span class="keyword">if</span> response.getcode() == <span class="number">200</span>:</span><br><span class="line">        print(response.geturl(), <span class="string">'--请求成功---'</span>)</span><br><span class="line">        <span class="comment"># print(response.info())  # 响应头(原始的header信息)</span></span><br><span class="line">        print(type(response.headers))</span><br><span class="line">        print(type(response))</span><br><span class="line">        print(response.status, response.code, response.getcode())</span><br><span class="line">        print(type(response.headers),  <span class="comment"># http.client.HTTPMessage</span></span><br><span class="line">              type(response.info()),  <span class="comment"># http.client.HTTPMessage</span></span><br><span class="line">              type(response.getheaders()))  <span class="comment"># list((key, value), ....)</span></span><br><span class="line">        print(response.getheaders())</span><br><span class="line">        print(response.getheader(<span class="string">'Content-Type'</span>))  <span class="comment"># 读取响应头的key</span></span><br><span class="line">        print(response.getheader(<span class="string">'Content-Length'</span>))  <span class="comment"># 不存在的key,返回None</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># html = response.readlines()  # 读取所有的网页信息</span></span><br><span class="line">        <span class="comment"># 读取响应文本数据的字符集</span></span><br><span class="line">        content_type = response.getheader(<span class="string">'Content-Type'</span>)  <span class="comment"># text/html; charset=utf-8</span></span><br><span class="line">        charset = content_type.split(<span class="string">';'</span>)[<span class="number">-1</span>].split(<span class="string">'='</span>)[<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line">        html = response.read().decode(encoding=charset)</span><br><span class="line">        print(html)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> open(<span class="string">'gushiwen.html'</span>, mode=<span class="string">'w'</span>, encoding=charset) <span class="keyword">as</span> file:</span><br><span class="line">            file.write(html)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(response.geturl(), <span class="string">'请求失败'</span>, response.code)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_url</span><span class="params">(url, filename)</span>:</span></span><br><span class="line">    <span class="comment"># 下载并保存网页</span></span><br><span class="line">    urlretrieve(url, filename)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_img</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> url.endswith(<span class="string">'.jpg'</span>) <span class="keyword">or</span> url.endswith(<span class="string">'.png'</span>):</span><br><span class="line">        urlretrieve(url, url.split(<span class="string">'/'</span>)[<span class="number">-1</span>])</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">    filename = md5_code(url)</span><br><span class="line">    resp = urlopen(url)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 读取响应的图片类型 jpg, png, gif</span></span><br><span class="line">    content_type = resp.getheader(<span class="string">'Content-Type'</span>)</span><br><span class="line">    img_type = content_type.split(<span class="string">';'</span>)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    filename += <span class="string">'.'</span>+img_type.split(<span class="string">"/"</span>)[<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> open(filename, mode=<span class="string">'wb'</span>) <span class="keyword">as</span> file:</span><br><span class="line">        file.write(resp.read())</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'保存图片%s 成功'</span> % filename)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">async_download</span><span class="params">(url)</span>:</span></span><br><span class="line">    Thread(target=save_img, args=(url, )).start()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment">#download('https://www.gushiwen.org/')</span></span><br><span class="line">    <span class="comment">#save_url('https://www.gushiwen.org/', '1.html')</span></span><br><span class="line">    <span class="comment">#save_img('https://ss0.baidu.com/6ONWsjip0QIZ8tyhnq/it/u=678166707,880764255&amp;fm=179&amp;app=42&amp;f=JPEG?w=121&amp;h=140')</span></span><br><span class="line">    url1 = <span class="string">'https://ss0.baidu.com/6ONWsjip0QIZ8tyhnq/it/u=678166707,880764255&amp;fm=179&amp;app=42&amp;f=JPEG?w=121&amp;h=140'</span></span><br><span class="line">    async_download(url1)</span><br><span class="line">    print(<span class="string">'--开始下载图片--'</span>, url1)</span><br></pre></td></tr></table></figure></div>
<h4 id="2-带有请求头的request"><a href="#2-带有请求头的request" class="headerlink" title="2.带有请求头的request"></a>2.带有请求头的request</h4><p>urlopen() 只负责下载<br>urlretrieve() 下载并存储到文件中</p>
<p>1） 在请求时，如何添加一个请求头<br>2） 如何发起post请求</p>
<div class="highlight-box" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#! /usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*-coding:UTF-8-*-</span></span><br><span class="line"><span class="comment"># __author__ : pighui</span></span><br><span class="line"><span class="comment"># __time__ : 2019-4-17 下午2:47</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen, Request</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> quote,urlencode</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="comment"># 声明请求头</span></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:66.0) Gecko/20100101 Firefox/66.0'</span>,</span><br><span class="line">        <span class="string">'Cookie'</span>: <span class="string">'__cfduid=dce29ab8587a6cafa917962eac2dfe2d11555483488; '</span></span><br><span class="line">                  <span class="string">'Hm_lvt_9b496e3d6adef11b924b6b261a56dff8=1555483491;'</span></span><br><span class="line">                  <span class="string">' Hm_lpvt_9b496e3d6adef11b924b6b261a56dff8=1555483514;'</span></span><br><span class="line">                  <span class="string">' BDTUJIAID=491cb6336da24c06bd13398fe2e150a6'</span>,</span><br><span class="line">        <span class="string">'Referer'</span>: <span class="string">'http://www.baidu.com/'</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建请求，可以添加请求头</span></span><br><span class="line">    request = Request(url, headers=headers)</span><br><span class="line"></span><br><span class="line">    response = urlopen(request)  <span class="comment"># 发起请求</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 判断请求是否成功</span></span><br><span class="line">    <span class="keyword">assert</span> response.code == <span class="number">200</span>  <span class="comment"># 如果断言失败，则抛出AssertionError</span></span><br><span class="line">    print(url, <span class="string">'请求成功!'</span>)</span><br><span class="line">    <span class="comment"># html = response.read()</span></span><br><span class="line"></span><br><span class="line">    lines = <span class="string">''</span></span><br><span class="line">    charset = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> response:  <span class="comment"># 可迭代的response</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> charset:</span><br><span class="line">            <span class="comment"># 尝试从正文中获取字符集</span></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                line_txt = line.decode()</span><br><span class="line">                lines += line_txt</span><br><span class="line">                <span class="keyword">if</span> line_txt.startswith(<span class="string">'&lt;meta'</span>):</span><br><span class="line">                    s = re.findall(<span class="string">r'charset=(\w+?)"'</span>, line_txt)</span><br><span class="line">                    <span class="keyword">if</span> s:</span><br><span class="line">                        charset = s[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            lines += line.decode(charset)</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    print(charset)</span><br><span class="line">    print(lines)</span><br><span class="line">    <span class="comment"># html = lines.decode(charset)</span></span><br><span class="line">    <span class="comment"># print(html)</span></span><br><span class="line">    <span class="comment"># print(response.getheader('Content-Type'))</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">post</span><span class="params">(url,data,headers)</span>:</span></span><br><span class="line">    <span class="comment">#实现post请求</span></span><br><span class="line">    <span class="comment">#设置Request的data参数，就是post请求</span></span><br><span class="line">    data = urlencode(data)</span><br><span class="line">    request = Request(url,data.encode(),headers)</span><br><span class="line">    <span class="comment">#发起请求</span></span><br><span class="line">    resp = urlopen(request)</span><br><span class="line">    <span class="keyword">if</span> resp.status == <span class="number">200</span>:</span><br><span class="line">        <span class="comment">#响应的数据是json类型</span></span><br><span class="line">        resp_data = resp.read()</span><br><span class="line">        <span class="comment">#获取字符集</span></span><br><span class="line">        content_type = resp.getheader(<span class="string">'Content-Type'</span>)</span><br><span class="line">        s= re.findall(<span class="string">r'charset=(\w+)'</span>, content_type)</span><br><span class="line">        <span class="keyword">if</span> s:</span><br><span class="line">            charset = s[<span class="number">0</span>]</span><br><span class="line">            json_data=resp_data.decode(charset)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            json_data=resp_data.decode()</span><br><span class="line">        <span class="comment">#print(json_data)</span></span><br><span class="line">        means = json.loads(json_data)</span><br><span class="line">        print(means.get(<span class="string">'dict_result'</span>).get(<span class="string">'simple_means'</span>).get(<span class="string">'word_means'</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment">#url = 'http://www.haha56.net/'</span></span><br><span class="line">    <span class="comment">#get(url)</span></span><br><span class="line">    url = <span class="string">'https://fanyi.baidu.com/v2transapi'</span></span><br><span class="line">    data = &#123;</span><br><span class="line">        <span class="string">'from'</span> : <span class="string">'en'</span>,</span><br><span class="line">        <span class="string">'to'</span> : <span class="string">'zh'</span>,</span><br><span class="line">        <span class="string">'query'</span>: <span class="string">'orange'</span>,</span><br><span class="line">        <span class="string">'simple_means_flag'</span>: <span class="number">3</span>,</span><br><span class="line">        <span class="string">'sign'</span>: <span class="string">'633076.871365'</span>,</span><br><span class="line">        <span class="string">'token'</span>: <span class="string">'a349279846f4d114c1a93ce82694603e'</span></span><br><span class="line">    &#125;</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:66.0) Gecko/20100101 Firefox/66.0'</span>,</span><br><span class="line">        <span class="string">'Cookie'</span>: <span class="string">'BAIDUID=CE4824AB95BCEDB8A95F17AD49690358:FG=1; BIDUPSID=CE4824AB95BCEDB8A95F17AD49690358; PSTM=1554878786; locale=zh; Hm_lvt_64ecd82404c51e03dc91cb9e8c025574=1555488877; Hm_lpvt_64ecd82404c51e03dc91cb9e8c025574=1555490031; from_lang_often=%5B%7B%22value%22%3A%22zh%22%2C%22text%22%3A%22%u4E2D%u6587%22%7D%2C%7B%22value%22%3A%22en%22%2C%22text%22%3A%22%u82F1%u8BED%22%7D%5D; to_lang_often=%5B%7B%22value%22%3A%22en%22%2C%22text%22%3A%22%u82F1%u8BED%22%7D%2C%7B%22value%22%3A%22zh%22%2C%22text%22%3A%22%u4E2D%u6587%22%7D%5D; REALTIME_TRANS_SWITCH=1; FANYI_WORD_SWITCH=1; HISTORY_SWITCH=1; SOUND_SPD_SWITCH=1; SOUND_PREFER_SWITCH=1'</span></span><br><span class="line">    &#125;</span><br><span class="line">    post(url,data,headers)</span><br></pre></td></tr></table></figure></div>
<h4 id="3-练习：爬取-糗事百科作者信息"><a href="#3-练习：爬取-糗事百科作者信息" class="headerlink" title="3.练习：爬取 糗事百科作者信息"></a>3.练习：爬取 糗事百科作者信息</h4><p>url= ‘<a href="https://www.qiushibaike.com/text/&#39;" target="_blank" rel="noopener">https://www.qiushibaike.com/text/&#39;</a><br>1)下载网页<br>2）获取信息<br>3）保存信息</p>
<div class="highlight-box" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true" data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#! /usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*-coding:UTF-8-*-</span></span><br><span class="line"><span class="comment">#__author__ : pighui</span></span><br><span class="line"><span class="comment">#__time__ : 2019-4-17 下午4:58</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">爬取 糗事百科中文字内容以及作者信息</span></span><br><span class="line"><span class="string">url= 'https://www.qiushibaike.com/text/'</span></span><br><span class="line"><span class="string">1)下载网页</span></span><br><span class="line"><span class="string">2）获取信息</span></span><br><span class="line"><span class="string">3）保存信息</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen, Request, urlretrieve</span><br><span class="line"><span class="keyword">import</span> ssl</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> util.md5_format <span class="keyword">import</span> md5_code</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ssl._create_default_https_context = ssl._create_unverified_context</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get</span><span class="params">(url)</span>:</span></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; '</span></span><br><span class="line">                      <span class="string">'rv:66.0) Gecko/20100101 Firefox/66.0'</span></span><br><span class="line">    &#125;</span><br><span class="line">    request = Request(url, headers = headers)</span><br><span class="line">    response = urlopen(request)</span><br><span class="line">    <span class="comment">#print(response.code,response.getheader('Content-Type'))</span></span><br><span class="line">    charset = re.findall(<span class="string">r'charset=(\w+)'</span>,</span><br><span class="line">                         response.getheader(<span class="string">'Content-Type'</span>))[<span class="number">0</span>]</span><br><span class="line">    html = response.read()</span><br><span class="line">    html = html.decode(charset)</span><br><span class="line">    <span class="keyword">return</span> html</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(html)</span>:</span></span><br><span class="line">    base_url = <span class="string">'//pic.qiushibaike.com/system/avtnew/'</span></span><br><span class="line">    s = re.findall(<span class="string">r'&lt;img src="//pic.qiushibaike.com/system/avtnew/(.+?)" alt="(.+?)"&gt;'</span>, html)</span><br><span class="line">    list = []</span><br><span class="line">    <span class="keyword">for</span> img_url,name <span class="keyword">in</span> s:</span><br><span class="line">        save(&#123;<span class="string">'img_url'</span>:<span class="string">'https:'</span> + base_url + img_url, <span class="string">'name'</span>:name&#125;)</span><br><span class="line">        list.append(<span class="string">'https:'</span> + base_url + img_url)</span><br><span class="line">    <span class="keyword">return</span> list</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save</span><span class="params">(item)</span>:</span></span><br><span class="line">    exist_header = os.path.exists(<span class="string">'qiushibaike_author.csv'</span>)</span><br><span class="line">    <span class="keyword">with</span> open (<span class="string">'qiushibaike_author.csv'</span>,<span class="string">'a'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        writer = csv.DictWriter(f, fieldnames=(<span class="string">'name'</span>, <span class="string">'img_url'</span>))</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> exist_header:</span><br><span class="line">            <span class="comment">#如果文件不存在，则表示第一次写入</span></span><br><span class="line">            writer.writeheader()</span><br><span class="line">        writer.writerow(item)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download_img</span><span class="params">(list)</span>:</span></span><br><span class="line">    <span class="comment">#下载头像(带扩展名，文件名md5加密)</span></span><br><span class="line">    <span class="comment">#https://pic.qiushibaike.com/system/avtnew/3100/31009050/thumb/20160122204121.jpg?imageView2/1/w/90/h/90</span></span><br><span class="line">    <span class="keyword">for</span> url <span class="keyword">in</span> list:</span><br><span class="line">        filename = md5_code(url) + <span class="string">'.'</span> + url.split(<span class="string">'?'</span>)[<span class="number">0</span>].split(<span class="string">'.'</span>)[<span class="number">-1</span>]</span><br><span class="line">        urlretrieve(url, filename)</span><br><span class="line">        print(<span class="string">'保存图片%s 成功'</span> % filename)</span><br><span class="line">    print(<span class="string">"下载完成"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    filename = md5_code(url)</span><br><span class="line">    resp = urlopen(url)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    url = <span class="string">'https://www.qiushibaike.com/text/'</span></span><br><span class="line">    html = get(url)</span><br><span class="line">    list = parse(html)</span><br><span class="line">    download_img(list)</span><br></pre></td></tr></table></figure></div>
<p>最后滴数据是这样子滴</p>
<p><img src="/爬虫/爬虫入门之Python中urllib库的使用/1.png" alt></p>

      
    </div>
    
      <footer class="article-footer">
        完
      </footer>
    
  </div>
  
    
<nav id="article-nav">
  <div class="article-nav-block">
    
      <a href="/爬虫/爬虫入门之使用xpath爬取糗事百科/" id="article-nav-newer" class="article-nav-link-wrap">
        <strong class="article-nav-caption"></strong>
        <div class="article-nav-title">
          
            爬虫入门之使用xpath爬取糗事百科
          
        </div>
      </a>
    
  </div>
  <div class="article-nav-block">
    
      <a href="/爬虫/对于Python中多线程的理解及实现方法/" id="article-nav-older" class="article-nav-link-wrap">
        <div class="article-nav-title">对于Python中多线程的理解及实现方法</div>
        <strong class="article-nav-caption"></strong>
      </a>
    
  </div>
</nav>

    
<div id="gitmentContainer"></div>
<link rel="stylesheet" href="https://www.xuhuiblog.cn/css/gitment.css">
<script type="text/javascript" src="https://www.xuhuiblog.cn/js/gitment.js"></script>
<script type="text/javascript" src="https://www.xuhuiblog.cn/js/md5.min.js"></script>
<script>
var gitment = new Gitment({
  id: md5(window.location.pathname.replace(/index.html/, "")),
  owner: 'pighui',
  repo: 'myblogdes',
  oauth: {
    client_id: '79535b24d59031961e6c',
    client_secret: '4f1907f09f33c1182feb2ddfeef33677e8e5ff36',
  },
})
gitment.render('gitmentContainer')
</script>

  
  
</article>
</section>
                <aside id="sidebar">
    <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="360" height="86" src="//music.163.com/outchain/player?type=2&id=1346998796&auto=0&height=66"></iframe>
    
        <div class="widget-box">
    <div class="avatar-box">
        <img class="avatar" src="/images/default-avatar.jpeg" title="图片来自网络">
        <h3 class="avatar-name">
            
                一介书生
            
        </h3>
        <p class="avatar-slogan">
            盼 君 金 榜 题 名 时 。
寒 窗 苦 读 数 十 载 ，
        </p>
    </div>
</div>


    
        
  <div class="widget-box">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Docker/">Docker</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hexo/">Hexo</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Kali/">Kali</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Ubuntu/">Ubuntu</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据分析/">数据分析</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/爬虫/">爬虫</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/面试题/">面试题</a></li></ul>
    </div>
  </div>


    
        
  <div class="widget-box">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Docker/">Docker</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hexo/">Hexo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Kali/">Kali</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Ubuntu/">Ubuntu</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/数据分析/">数据分析</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/机器学习/">机器学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/测试/">测试</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/爬虫/">爬虫</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/面试题/">面试题</a></li></ul>
    </div>
  </div>


    
        
  <div class="widget-box">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/Docker/" style="font-size: 11.43px;">Docker</a> <a href="/tags/Hexo/" style="font-size: 12.86px;">Hexo</a> <a href="/tags/Kali/" style="font-size: 10px;">Kali</a> <a href="/tags/Python/" style="font-size: 20px;">Python</a> <a href="/tags/Ubuntu/" style="font-size: 15.71px;">Ubuntu</a> <a href="/tags/数据分析/" style="font-size: 18.57px;">数据分析</a> <a href="/tags/机器学习/" style="font-size: 14.29px;">机器学习</a> <a href="/tags/测试/" style="font-size: 11.43px;">测试</a> <a href="/tags/爬虫/" style="font-size: 17.14px;">爬虫</a> <a href="/tags/面试题/" style="font-size: 10px;">面试题</a>
    </div>
  </div>

    
        
  <div class="widget-box">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">五月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/04/">四月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">三月 2019</a></li></ul>
    </div>
  </div>

    
        
  <div class="widget-box">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/机器学习/人脸自动补全/">人脸自动补全</a>
          </li>
        
          <li>
            <a href="/机器学习/Logistics回归和数字识别/">Logistics回归和数字识别</a>
          </li>
        
          <li>
            <a href="/机器学习/LinearRegression线性回归/">LinearRegression线性回归</a>
          </li>
        
          <li>
            <a href="/机器学习/KNN-手写数字识别/">KNN-手写数字识别</a>
          </li>
        
          <li>
            <a href="/机器学习/K-近邻算法-KNN/">K-近邻算法（KNN）</a>
          </li>
        
      </ul>
    </div>
  </div>

    
          <div class="widget-box">
    <h3 class="widget-title">友链</h3>
    <div class="widget">
      
        <a style="display: block;" href="https://yiluyanxia.github.io/" title target="_blank">一路眼瞎</a>
      
        <a style="display: block;" href="https://wljsky.cn/" title target="_blank">钧金</a>
      
    </div>
  </div>

    
</aside>
            </div>
            <footer id="footer">
    <!-- 百度推送 -->
    <script>
        (function () {
            var bp = document.createElement('script');
            var curProtocol = window.location.protocol.split(':')[0];
            if (curProtocol === 'https') {
                bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
            } else {
                bp.src = 'http://push.zhanzhang.baidu.com/push.js';
            }
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(bp, s);
        })();
    </script>

    <!-- 百度统计 -->
    <script>
        var _hmt = _hmt || [];
        (function () {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?58e88d550a3485e4fa9494eb391c7e47";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();
    </script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=UA-135687698-1"></script> -->
    <script src="/js/google.js"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());
        gtag('set', {'user_id': 'UA-135687698-1'});
        gtag('config', 'UA-135687698-1');
    </script>
    <div class="foot-box global-width">
        &copy;Copyright&nbsp;2019 一介书生<br>
        驱动于 <a href="http://hexo.io/" target="_blank">Hexo</a>
        &nbsp;|&nbsp;主题 <a href="https://github.com/yiluyanxia/hexo-theme-antiquity">antiquity</a>
        <br>
        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
        <span id="busuanzi_container_site_pv">阁下是第<span id="busuanzi_value_site_pv"></span>个访客</span>
        <br>
        豫ICP备<a href="http://ha.beian.miit.gov.cn/">19008962</a>号
    </div>
</footer>
            <script src="//libs.baidu.com/jquery/2.1.4/jquery.min.js"></script>
<script>
    if (!window.jQuery) {
        var script = document.createElement('script');
        script.src = "/js/jquery.min.js";
        document.body.write(script);
    }
</script>

    <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
    <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



        </div>
        <nav id="mobile-nav" class="mobile-nav-box">
  <div class="mobile-nav-img mobile-nav-top"></div>
  
    <a href="/" class="mobile-nav-link">首页</a>
  
    <a href="https://github.com/pighui" class="mobile-nav-link">基友</a>
  
    <a href="/archives" class="mobile-nav-link">文章</a>
  
    <a href="/me" class="mobile-nav-link">简历</a>
  
    <a href="/snow" class="mobile-nav-link">看雪</a>
  
  <div class="mobile-nav-img  mobile-nav-bottom"></div>
</nav>
    </div>
    <script type="text/javascript" src="/js/jquery.min.js"></script>
    <script src="/js/love.js"></script>
    <script src="/js/snowy.js"></script>
    <style type="text/css">.snow-container {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            pointer-events: none;
            z-index: 100001;
        }</style>
    <div class="snow-container"></div>
</body>
</html>