---
title: 简历
date: 2019-11-11 16:35:58
comments: True
---

# 个人信息

 - 续辉/男/1995
 - 本科/青海民族大学计算机科学与技术专业
 - 工作年限：2年
 - 技术博客：https://www.xuhuiblog.cn
 - Github：https://github.com/pighui
 - 期望职位：Python开发工程师
 - 期望薪资：税前月薪8-10K
 - 期望城市：西安

# 联系方式
- 手机：18518042602（北京）
- Email：jujuhui233@gmail.com 
- QQ/微信号：957824117/TNT1258

---

# 工作经历
**北京基金小镇控股有限公司**

**职位名称：**Python全栈工程师

**工作时间：**2017年11月 – 2019年11月

**工作描述：**

1. 负责基础数据的爬取、预处理等环节的技术支持与维护。

2. 负责产品后台服务的测试与维护。

3. 负责日志系统的设计与开发。

4. 负责后端接口的设计、测试与维护。

**项目经历：**

**项目一：行情中心数据服务平台**

**项目描述：**为及时把握市场动向，获取最新数据，爬取天天基金网（隶属东方财富网旗下基金平台） 新股|基金|港股|期货 等板块数据，实现定时、增量爬取，进行数据清洗和数据入库。

**责任描述**：

1. 负责项目的架构设计、开发环境搭建；

2. 负责实现数据提取、数据存储；

3. 负责定时任务的设计与实现；

4. 负责自动化Shell脚本的编写；

5. 负责爬虫的服务器部署。

**技术描述**：

1. 基于Scrapy框架开发；

2. 使用MySql数据库做数据持久化存储；

3. 使用Selenium中间件技术获取页面数据；

4. 实现自动化爬虫Shell脚本；

5. 使用Linux下Crontab实现定时任务；

6. 使用Scrapyd服务部署爬虫。

**项目二：基金业务服务中心OA系统**

**项目描述：**为适应公司发展，系统的管理公司业务数据，开发出适合公司当前运营模式的后台管理系统，使业务流程化，数据可视化，管理规范化。

**责任描述：**

1. 负责注册登录页面以及权限管理的设计与实现；

2. 负责项目的云服务器部署；

3. 负责日志系统的设计与完善。

**技术描述：**

1. 基于Django框架开发，使用template模板；

2. 使用CBV模式处理请求；

3. 使用Pyecharts实现部分数据可视化；

4. 使用MySQL做数据持久化存储；

5. 使用Redis做数据缓存；

6. 使用uWSGI + Nginx服务器部署。

**项目三：Fund town APP项目**

**项目描述：**为扩展公司基金业务，便于广大股民购买基金、证券，及时掌握行业动态，在此基础上，开发		 出面向用户的Fund town APP。

**责任描述：**

1. 负责后端接口的设计与实现；

2. 负责接口的测试与文档编写；

3. 负责服务器部署与并发量测试。

**技术描述：**

1. 使用Flask框架，前后端分离；

2. 使用Restful API规范设计接口；

3. 使用SQLachemy模块实现ORM模型映射；

4. 使用MySQL做数据存储；

5. 使用Redis数据库做数据缓存；

6. 使用Elasticsearch搜索服务器实现快速搜索；
7. 使用Nginx服务器+Docker容器部署。

---

# 开源项目和作品
## 开源项目
 - [dushu](<https://github.com/pighui/dushu>)：基于Scrapy框架的规则爬虫，提取读书网所有图书信息，包括图书名、作者、价格、出版商、出版日期、条形码编号、详情页面链接等信息，并写入mysql数据库中。
 - [luoxia](<https://github.com/pighui/luoxia>)：基于Scrapy框架的非规则爬虫，按章节下载落霞小说网所有小说文本。
 - [cosmetics_shop](<https://github.com/pighui/cosmetics_shop>)：使用Django开发的B2C模式的彩妆网。
 - [my_proxy_list](<https://github.com/pighui/my_proxy_list>)：使用flask+mysql+爬虫实现IP代理池。

## 技术文章

- [在Ubuntu18.04服务器上部署Hexo博客](https://www.xuhuiblog.cn/Hexo/%E5%9C%A8Ubuntu18-04%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E9%83%A8%E7%BD%B2Hexo%E5%8D%9A%E5%AE%A2/)

- [Python爬虫之使用bs4爬取BOSS直聘](https://www.xuhuiblog.cn/%E7%88%AC%E8%99%AB/Python%E7%88%AC%E8%99%AB%E4%B9%8B%E4%BD%BF%E7%94%A8bs4%E7%88%AC%E5%8F%96BOSS%E7%9B%B4%E8%81%98/)
- [在docker中安装elasticsearch以及用法的介绍)](https://www.xuhuiblog.cn/Docker/在docker中安装elasticsearch以及用法的介绍/) 

# 技能清单

- Python基础扎实，有良好的编码习惯。
- 熟悉Python多线程、多进程、协程的实现原理。
- 熟悉JavaScript、Ajax、JQuery、CSS、HTML等WEB前端技术。
- 熟练使用Django、Flask等主流web框架，熟悉Tornado框架。
- 熟练使用MySQL、Redis数据库，熟悉MongoDB数据库。
- 熟练使用Scrapy爬虫框架，掌握Scrapy-redis框架。
- 熟练使用Requests、Urllib等网络请求库。
- 熟练使用Xpath、BS4、Selenium等工具实现数据提取。
- 熟悉Linux/类Uninx系统，掌握其常用命令的使用，对Shell编程有一定了解。
- 熟悉Nginx、Docker、Openresty、Gunicorn等部署工具和第三方包，有云服务器搭建经验。、
- 熟练使用Git代码管理工具，熟悉Github、Gitee、Gitlab等代码托管仓库。
- 有一定的英语阅读能力。

---

# 致谢
感谢您花时间阅读我的简历，期待能有机会和您共事。
